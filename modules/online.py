import os
from dotenv import load_dotenv
from openai import OpenAI

# üîê Carrega vari√°veis do arquivo .env localizado na pasta 'env'
load_dotenv(dotenv_path=os.path.join("env", ".env"))

# üîë Obt√©m a chave da API
api_key = os.getenv("OPENROUTER_API_KEY")
if not api_key:
    raise ValueError("‚ùå Chave de API n√£o encontrada. Verifique o arquivo env/.env e a vari√°vel OPENROUTER_API_KEY.")

# üîó Inicializa o cliente da OpenRouter
client = OpenAI(
    api_key=api_key,
    base_url="https://openrouter.ai/api/v1"
)

# üß† Hist√≥rico de conversa para manter o contexto
conversa = [
    {"role": "system", "content": "Voc√™ √© um assistente √∫til que responde em portugu√™s do Brasil."}
]

def gerar_resposta_online(prompt: str) -> str:
    """
    Gera uma resposta usando o modelo de IA gratuito do OpenRouter.

    Args:
        prompt (str): A pergunta ou mensagem do usu√°rio.

    Returns:
        str: A resposta gerada pela IA ou uma mensagem de erro.
    """
    try:
        # Adiciona a entrada do usu√°rio ao hist√≥rico
        conversa.append({"role": "user", "content": prompt})

        # üîÅ Limita o hist√≥rico a 20 mensagens (mant√©m o system + √∫ltimas 19)
        if len(conversa) > 20:
            conversa[:] = [conversa[0]] + conversa[-19:]

        # Chamada √† API
        response = client.chat.completions.create(
            model="mistralai/mistral-7b-instruct:free",  # ‚úÖ modelo gratuito
            messages=conversa,
            temperature=0.7,
            max_tokens=500
        )

        # Extrai e retorna a resposta
        resposta = response.choices[0].message.content.strip()
        conversa.append({"role": "assistant", "content": resposta})
        return resposta

    except Exception as e:
        return f"‚ö†Ô∏è Erro ao gerar resposta: {str(e)}"










